#%% Change working directory from the workspace root to the ipynb file location. Turn this addition off with the DataScience.changeDirOnImportExport setting
import os
try:
	os.chdir(os.path.join(os.getcwd(), 'HW4\Scripts04\2'))
	print(os.getcwd())
except:
	pass
sdfsdfsdfsfdsdfsfd
#%%
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

#%% [markdown]
# **Логистическая регрессия** 
# 
# Логистическая регрессия используется для задач классификации, 
# 
# при этом вычисляется вероятность принадлежности 
# 
# события к определенному классу.
# 
# Задача алгоритма логистической регрессии - найти 
# 
# подходящие коэффициенты w при признаках x:
# 
# ### $z = w_0 + w_1 * x_1 + w_2 * x_2 + ... + w_m * x_m$
# 
# Величина z помещается в сигмоидную функцию для вычисления вероятности:
# 
# ## $f(x) = \frac{1}{1 + e^{-z}}$
# 
# Значение f(x) будет расположено на отрезке [0, 1].
# 
# f(x) - вероятность отнесения события к классу 1,
# 
# 1 - f(x) - вероятность отнесения события к классу 0.
#%% [markdown]
# #### Log loss
#%% [markdown]
# Алгоритм логистической регрессии минимизирует величину logloss:
#     
# $ logloss = - y*ln(p) - (1 - y) * ln(1 - p) $
# 
# где y - истинное значение (0 или 1),
# 
# p - вычисленная алгоритмом вероятность того, что событие принадлежит классу 1
#%% [markdown]
# #### Titanic
#%% [markdown]
# Для изучения классификации мы будем использовать 
# 
# датасет с информацией о пассажирах **Titanic** с сайта Kaggle.com
# 
# Ссылка: https://www.kaggle.com/c/titanic/data
# 
# Нам понадобится файл под названием train.csv, который мы поместим в папку input:

#%%
data = pd.read_csv('input/train.csv')


#%%
data.head(10)

#%% [markdown]
# Установим в качестве индекса PassengerId - так нам будет проще отслеживать, с информацией о  каком пассажире мы работаем

#%%
data = data.set_index('PassengerId')


#%%
data.head()


#%%
data.columns

#%% [markdown]
# Наша задача - определить, выжил ли человек при крушении Титаника. 
# 
# В поле Survived выжившие пассажиры обозначены единицей, а утонувшие - нулём.

#%%
target = 'Survived'


#%%
y = data[target]


#%%
X = data.drop(target, axis=1)

#%% [markdown]
# #### Изучение качества данных и их очистка

#%%
X.info()

#%% [markdown]
# В поле Cabin слишком много пропущенных значений,
# 
# в этом уроке мы не будем его использовать.
# 
# Столбцы Name и Ticket также в этот раз не рассматриваем. 
# 
# Удалим эти поля:

#%%
X = X.drop(['Cabin', 'Name', 'Ticket'], axis=1)

#%% [markdown]
# В поле возраст 20% значений не заполнено. Заменим пропущенные значения на значения среднего возраста.

#%%
mean_age = X['Age'].mean()
mean_age


#%%
X['Age'] = X['Age'].fillna(mean_age)


#%%
X['Age'].unique()

#%% [markdown]
# В поле Embarked, которое является текстовым, не хватает двух значений,
# 
# заполним пропущенные значения наиболее часто встречающимся значением (мода)

#%%
X['Embarked'].value_counts()


#%%
embarked_mode = X['Embarked'].mode()[0]
embarked_mode


#%%
X['Embarked'] = X['Embarked'].fillna(embarked_mode)


#%%
X['Embarked'].value_counts()


#%%
X.info()

#%% [markdown]
# #### Работа с категориальными признаками
#%% [markdown]
# Признак пола пассажира (Sex) - категориальная переменная. Так как в ней два класса, 
# 
# то мы можем представить одной колонкой со
# 
# значениями 0 и 1:

#%%
X['Sex'].value_counts()


#%%
X['Sex'] = (X['Sex'] == 'female').astype(int)


#%%
X['Sex'].value_counts()

#%% [markdown]
# Еще одна категориальная переменная - Embarked.
# 
# Преобразуем её значения в dummy-переменные.
# 
# Теперь каждому её значению будет отведен отдельный столбец,
# 
# в котором возможны два числа:
#     
#     1 (переменная равна данному значению),
#                                       
#     0 (переменная не равна данному значению)

#%%
X = pd.get_dummies(X)

#%% [markdown]
# Переменная Embarked преобразовалась в дамми-переменные Embarked_C, Embarked_Q, Embarked_S:

#%%
X.columns


#%%
X.info()


#%%
X.head(10)

#%% [markdown]
# Переменную Pclass можно отправить в модель в таком виде, 
# 
# какая она есть сейчас, так как она представлена числами,
# 
# но так как это все-таки не количественная переменная 
# 
# (например, нельзя сказать, что между классами 1 и 2 такая же "разность",
#                                                     
# как и между классами 2 и 3), то ее так же переведем в дамми-переменные.
# 
# Для этого поменяем ее тип данных на category
# 
# и применим еще раз применим функцию get_dummies
# 
# ко всему датафрейму.
# 
# Эта функция переведет в дамми-переменные все нечисловые признаки.

#%%
X['Pclass'].unique()


#%%
X['Pclass'] = X['Pclass'].astype('category')


#%%
X = pd.get_dummies(X)


#%%
X.columns

#%% [markdown]
# #### Цель разбиения данных на тренировочный, валидационный и тестовый датасеты
#%% [markdown]
# В этот раз мы будем более работать с разделением данных для модели более тщательно,
# 
# мы разобьем данные из файла train.csv на две части:
# 
# тренировочный набор данных (признаки в X_train, целевая переменная в y_train)
# 
# и валидационный (соответственно X_valid и y_valid).
# 
# На тренировочном датасете мы будем строить модель, а на валидационном - проверять её качество.
# 
# После проверки на валидационном сете можно будет окончательно проверить модель на тестовом сете 
# 
# (содержится в файле test.csv по вышеуказанной ссылке - 
# 
# фактическое значение целевой переменной в тестовом наборе отсутствует,
# 
# рекомендуем самостоятельно проверить точность данных при отправке решения на странице соревнования).

#%%
# Параметр test_size будет определять, какую долю данных 
# из train.csv мы берем для валидационного датасета
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=42)

#%% [markdown]
# #### Построение модели
#%% [markdown]
# В начале работы над любой задачей рекомендуется сначала сделать простую модель, 
# 
# не затрачивая большого количества времени. 
# 
# Затем можно будет оценивать новые модели, сравнивая их качество 
# 
# с качеством первоначальной (базовой) модели.
#%% [markdown]
# Сначала посмотрим на информацию о признаках:

#%%
X_train.info()

#%% [markdown]
# Все признаки - числовые, поэтому мы можем построить модель, используя все признаки.

#%%
lr = LogisticRegression()


#%%
lr.fit(X_train, y_train)


#%%
y_pred = lr.predict(X_valid)


#%%
y_pred

#%% [markdown]
# Метрика Accuracy (доля правильных ответов)

#%%
from sklearn.metrics import accuracy_score


#%%
accuracy_score(y_valid, y_pred)

#%% [markdown]
# Можно сравнить с Accuracy на тренировочном датасете

#%%
y_pred_train = lr.predict(X_train)


#%%
accuracy_score(y_train, y_pred_train)

#%% [markdown]
# #### Вычисление вероятности событий

#%%
y_proba = lr.predict_proba(X_valid)


#%%
# Вероятности событий 0 и 1 для каждого пассажира
y_proba

#%% [markdown]
# Нас интересует вероятность события 1 (правый столбец) - 
# 
# при получении ответа значения из него округляются до 0 или до 1
#%% [markdown]
# #### Сохранение данных
#%% [markdown]
# Сохраним обработанные данные, они пригодятся для следующих уроков

#%%
X_train.to_pickle('X_train.pkl')
y_train.to_pickle('y_train.pkl')

X_valid.to_pickle('X_valid.pkl')
y_valid.to_pickle('y_valid.pkl')


#%%



